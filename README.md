# ğŸš• AnÃ¡lisis de Datos de NYC Taxi en Tiempo Real

## Spark Streaming + Apache Kafka + Batch Processing

Sistema completo de anÃ¡lisis de datos de taxis de Nueva York utilizando Apache Spark para procesamiento batch y Apache Spark Streaming con Apache Kafka para anÃ¡lisis en tiempo real.


## ğŸ¯ DescripciÃ³n del Proyecto

Este proyecto implementa un sistema completo de anÃ¡lisis de datos con **dos componentes principales**:

1. **Procesamiento Batch**: AnÃ¡lisis exploratorio y limpieza de datos histÃ³ricos
2. **Procesamiento Streaming**: AnÃ¡lisis en tiempo real de datos continuos

Ambos componentes procesan informaciÃ³n de viajes de taxis en la ciudad de Nueva York para obtener insights sobre demanda, tarifas, rutas y patrones de comportamiento.

### Problema a Resolver

**"Sistema Integral de AnÃ¡lisis de Demanda de Taxis"**

El sistema permite:
- âœ… AnÃ¡lisis histÃ³rico de grandes volÃºmenes de datos (Batch)
- âœ… Limpieza y transformaciÃ³n de datos
- âœ… AnÃ¡lisis exploratorio completo (EDA)
- âœ… Monitoreo en tiempo real de demanda por zonas
- âœ… CÃ¡lculo de mÃ©tricas en ventanas de tiempo
- âœ… DetecciÃ³n de patrones y anomalÃ­as

---

## ğŸ› ï¸ TecnologÃ­as Utilizadas

| TecnologÃ­a | VersiÃ³n | Uso |
|------------|---------|-----|
| **Apache Spark** | 3.5.3 | Procesamiento batch y streaming |
| **Apache Kafka** | 3.6.2 | Plataforma de streaming distribuido |
| **Apache ZooKeeper** | Incluido | CoordinaciÃ³n de servicios |
| **Python** | 3.x | Lenguaje de programaciÃ³n |
| **PySpark** | 3.5.3 | API de Spark para Python |
| **kafka-python** | Latest | Cliente de Kafka |

---

## ğŸ“¦ Requisitos Previos

### Hardware
- MÃ­nimo 4GB RAM
- 10GB de espacio en disco

### Software
- Sistema Operativo: Linux (Ubuntu/Debian)
- Java JDK 8 o superior
- Python 3.7 o superior
- Apache Hadoop (configurado)
- Apache Spark (configurado)

### Credenciales VM
```
Usuario: vboxuser
Password: bigdata
```

---

## ğŸš€ InstalaciÃ³n

### 1. Clonar el Repositorio

```bash
git clone https://github.com/Byronsuaza/BIGDATA-TAREA-3.git
cd BIGDATA-TAREA-3
```

### 2. Instalar Dependencias Python

```bash
# OpciÃ³n 1: Usando apt (Recomendado)
sudo apt update
sudo apt install python3-kafka

# OpciÃ³n 2: Usando pip
pip install kafka-python --break-system-packages
```

### 3. Instalar Apache Kafka

```bash
# Descargar Kafka
cd ~
wget https://archive.apache.org/dist/kafka/3.6.2/kafka_2.13-3.6.2.tgz

# Descomprimir
tar -xzf kafka_2.13-3.6.2.tgz

# Mover a /opt
sudo mv kafka_2.13-3.6.2 /opt/Kafka

# Verificar
ls /opt/Kafka
```

---

## ğŸ“Š Componente 1: Procesamiento Batch

### DescripciÃ³n

El componente batch realiza anÃ¡lisis exploratorio completo sobre datos histÃ³ricos, incluyendo limpieza, transformaciÃ³n y generaciÃ³n de insights.

### 1.1 Generar Dataset

```bash
# Crear el generador
nano generate_taxi_dataset.py
# Copiar contenido del archivo generate_taxi_dataset.py del repositorio
# Guardar: Ctrl+O, Enter, Ctrl+X

# Ejecutar generador
python3 generate_taxi_dataset.py
```

**Salida esperada:**
```
ğŸš• Generando dataset con 50000 registros...
   Generados 10000/50000 registros...
   Generados 20000/50000 registros...
   ...
âœ… Dataset generado exitosamente: nyc_taxi_data.csv
ğŸ“Š Total de registros: 50000
ğŸ“ TamaÃ±o aproximado: 7.50 MB
```

### 1.2 Ejecutar Procesamiento Batch

```bash
# Crear el script
nano batch_processing_taxi.py
# Copiar contenido del archivo batch_processing_taxi.py del repositorio
# Guardar: Ctrl+O, Enter, Ctrl+X

# Ejecutar con Spark
spark-submit batch_processing_taxi.py
```

### 1.3 Operaciones Realizadas

#### âœ… Carga de Datos
- Lee 50,000 registros desde CSV
- Infiere esquema automÃ¡ticamente
- Muestra estructura de datos

#### âœ… AnÃ¡lisis Exploratorio (EDA)
- EstadÃ­sticas descriptivas completas
- Distribuciones por zona geogrÃ¡fica
- AnÃ¡lisis por tipo de pago
- IdentificaciÃ³n de rutas populares
- MÃ©tricas de ingresos

#### âœ… Limpieza de Datos
- EliminaciÃ³n de valores nulos
- Filtrado de valores anÃ³malos:
  - Pasajeros = 0
  - Distancia = 0
  - Tarifas negativas
  - Outliers extremos (> $500)
- EliminaciÃ³n de duplicados

#### âœ… TransformaciÃ³n
Columnas derivadas creadas:
- `trip_duration_minutes`: DuraciÃ³n del viaje
- `fare_per_mile`: Tarifa por milla
- `tip_percentage`: Porcentaje de propina

#### âœ… Almacenamiento
Resultados guardados en `output_batch_processing/`:
- **clean_data/**: Datos limpios (Parquet)
- **zone_analysis/**: AnÃ¡lisis por zona (CSV)
- **payment_analysis/**: AnÃ¡lisis de pagos (CSV)
- **popular_routes/**: Top 100 rutas (CSV)

### 1.4 Ejemplo de Resultados Batch

```
ğŸ—ºï¸  AnÃ¡lisis por Zona de Recogida:
+-------------+-----------+--------+------------+-------+-------------+
|pickup_zone  |total_trips|avg_fare|avg_distance|avg_tip|total_revenue|
+-------------+-----------+--------+------------+-------+-------------+
|Manhattan    |15234      |24.56   |3.45        |4.23   |423567.89    |
|Brooklyn     |12456      |19.34   |5.67        |2.89   |278945.12    |
|Queens       |10987      |21.45   |6.78        |3.12   |256789.45    |
|Bronx        |5678       |18.90   |7.23        |2.45   |123456.78    |
|Staten Island|3195       |27.89   |10.45       |3.67   |98765.43     |
+-------------+-----------+--------+------------+-------+-------------+
```

---

## âš¡ Componente 2: Procesamiento en Tiempo Real

### DescripciÃ³n

Sistema de streaming que procesa datos de taxis en tiempo real utilizando Kafka como broker de mensajes y Spark Streaming para anÃ¡lisis continuo.

### 2.1 Configurar Kafka

#### Iniciar ZooKeeper
```bash
sudo /opt/Kafka/bin/zookeeper-server-start.sh /opt/Kafka/config/zookeeper.properties &
```
â° Espera 5-10 segundos y presiona **Enter**

#### Iniciar Kafka Server
```bash
sudo /opt/Kafka/bin/kafka-server-start.sh /opt/Kafka/config/server.properties &
```
â° Espera 5-10 segundos y presiona **Enter**

#### Crear Topic
```bash
/opt/Kafka/bin/kafka-topics.sh --create \
  --bootstrap-server localhost:9092 \
  --replication-factor 1 \
  --partitions 1 \
  --topic taxi_trips
```

âœ… DeberÃ­as ver: `Created topic taxi_trips`

### 2.2 Ejecutar Producer (Terminal 1)

```bash
# Crear el productor
nano kafka_producer_taxi.py
# Copiar contenido del repositorio
# Guardar: Ctrl+O, Enter, Ctrl+X

# Ejecutar
python3 kafka_producer_taxi.py
```

**Salida esperada:**
```
ğŸš• NYC Taxi Data Producer - Iniciado
Enviando datos a Kafka topic: taxi_trips
--------------------------------------------------
âœ… Enviado: Trip 456789 | Manhattan â†’ Brooklyn | $23.50 | 3.2 miles
âœ… Enviado: Trip 234567 | Queens â†’ Manhattan | $31.00 | 8.5 miles
```

### 2.3 Ejecutar Consumer (Terminal 2 - Nueva conexiÃ³n SSH)

```bash
# Crear el consumidor
nano spark_streaming_consumer_taxi.py
# Copiar contenido del repositorio
# Guardar: Ctrl+O, Enter, Ctrl+X

# Ejecutar con Spark
spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.3 spark_streaming_consumer_taxi.py
```

**Salida esperada:**
```
ğŸš• NYC Taxi Streaming Analysis - Iniciado
============================================================

-------------------------------------------
Batch: 0
-------------------------------------------
+------------------------------------------+-------------+-----------+--------+
|window                                    |pickup_zone  |total_trips|avg_fare|
+------------------------------------------+-------------+-----------+--------+
|{2025-10-27 14:30:00, 2025-10-27 14:31:00}|Manhattan    |60         |26.80   |
|{2025-10-27 14:30:00, 2025-10-27 14:31:00}|Brooklyn     |45         |19.35   |
+------------------------------------------+-------------+-----------+--------+
```

### 2.4 Monitorear con Spark UI

```
http://[TU-IP]:4040
```

Ejemplo: `http://192.168.1.7:4040`

### 2.5 Detener EjecuciÃ³n

En ambas terminales: **Ctrl + C**

---

## ğŸ—ï¸ Arquitectura del Sistema

### Arquitectura General

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     PROCESAMIENTO BATCH                         â”‚
â”‚                                                                 â”‚
â”‚  CSV Dataset  â†’  Spark Batch  â†’  Limpieza/EDA  â†’  Resultados   â”‚
â”‚  (50K registros)    (PySpark)     (AnÃ¡lisis)      (Parquet/CSV)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  PROCESAMIENTO EN TIEMPO REAL                   â”‚
â”‚                                                                 â”‚
â”‚  Producer  â†’  Kafka Topic  â†’  Spark Streaming  â†’  Dashboard    â”‚
â”‚  (Python)     (taxi_trips)     (PySpark)          (Console/UI) â”‚
â”‚                                                                 â”‚
â”‚  Genera datos  â”‚  Buffer     â”‚  Ventanas de    â”‚  MÃ©tricas en  â”‚
â”‚  simulados     â”‚  streaming  â”‚  1 minuto       â”‚  tiempo real  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flujo de Datos - Streaming

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  kafka_producer â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ Apache Kafka â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ spark_consumer  â”‚
â”‚   _taxi.py      â”‚         â”‚ Topic:       â”‚         â”‚    _taxi.py     â”‚
â”‚                 â”‚         â”‚ taxi_trips   â”‚         â”‚                 â”‚
â”‚ Genera 1 viaje  â”‚         â”‚              â”‚         â”‚ Ventanas de     â”‚
â”‚ por segundo     â”‚         â”‚ Queue/Buffer â”‚         â”‚ tiempo (1 min)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                â”‚
                                                                â–¼
                                                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                      â”‚  AnÃ¡lisis       â”‚
                                                      â”‚  â€¢ Trips/zona   â”‚
                                                      â”‚  â€¢ Tarifas avg  â”‚
                                                      â”‚  â€¢ Ingresos     â”‚
                                                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Resultados y AnÃ¡lisis

### MÃ©tricas del Sistema Batch

| MÃ©trica | Valor |
|---------|-------|
| Registros procesados | 50,000 |
| Registros limpios | ~47,500 |
| Registros eliminados | ~2,500 |
| Tiempo de procesamiento | ~45 segundos |
| Archivos generados | 4 |

### MÃ©tricas del Sistema Streaming

| MÃ©trica | DescripciÃ³n |
|---------|-------------|
| Frecuencia de datos | 1 registro/segundo |
| Ventana de tiempo | 1 minuto |
| Zonas monitoreadas | 5 |
| MÃ©tricas por ventana | 5 |
| Latencia | < 2 segundos |

### Insights Generados

#### Batch Processing
- âœ… DistribuciÃ³n de viajes por zona
- âœ… AnÃ¡lisis de tarifas y propinas
- âœ… IdentificaciÃ³n de rutas populares
- âœ… DetecciÃ³n de valores anÃ³malos
- âœ… Patrones de pago

#### Streaming
- âœ… Demanda en tiempo real por zona
- âœ… Ingresos por minuto
- âœ… OcupaciÃ³n promedio
- âœ… Distancias promedio
- âœ… Alertas de picos de demanda

---

## ğŸ“ Estructura del Proyecto

```
BIGDATA-TAREA-3/
â”‚
â”œâ”€â”€ generate_taxi_dataset.py              # Generador de datos
â”œâ”€â”€ batch_processing_taxi.py              # Procesamiento batch
â”œâ”€â”€ kafka_producer_taxi.py                # Producer de streaming
â”œâ”€â”€ spark_streaming_consumer_taxi.py      # Consumer de streaming
â”œâ”€â”€ README.md                             # Este archivo
â”‚
â”œâ”€â”€ nyc_taxi_data.csv                     # Dataset generado
â”‚
â””â”€â”€ output_batch_processing/              # Resultados batch
    â”œâ”€â”€ clean_data/                       # Datos limpios (Parquet)
    â”œâ”€â”€ zone_analysis/                    # AnÃ¡lisis por zona (CSV)
    â”œâ”€â”€ payment_analysis/                 # AnÃ¡lisis de pagos (CSV)
    â””â”€â”€ popular_routes/                   # Rutas populares (CSV)
```

---

## ğŸ“š Dataset de Referencia

Este proyecto utiliza **datos simulados** basados en el dataset real:

- **Nombre:** NYC Yellow Taxi Trip Data
- **Fuente:** NYC Taxi & Limousine Commission (TLC)
- **Disponible en:**
  - Kaggle: https://www.kaggle.com/datasets/elemento/nyc-yellow-taxi-trip-data
  - NYC Open Data: https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page
- **Volumen real:** 3+ mil millones de registros histÃ³ricos
- **Simulado:** 50,000 registros generados

---


## ğŸ‘¨â€ğŸ’» Autor

**Byron Suaza**
